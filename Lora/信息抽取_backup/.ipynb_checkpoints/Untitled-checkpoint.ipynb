{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767cdd92-d42a-4335-95b2-d00bbd76fc27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'message_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     16\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# model=\"Qwen-7B-Lora_Chat\",\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquant_lora\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 21\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessage_list\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \n\u001b[1;32m     25\u001b[0m     output_token \u001b[38;5;241m=\u001b[39m chat_response\u001b[38;5;241m.\u001b[39musage\u001b[38;5;241m.\u001b[39mcompletion_tokens\n",
      "\u001b[0;31mNameError\u001b[0m: name 'message_list' is not defined"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:1122/v1\"\n",
    "import time\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "# prompts_list = [\"告诉我有关北京的特产\"] * 10 \n",
    "message = [ {\"role\": \"user\", \"content\": '告诉我有关北京的特产'}] \n",
    "i = 0\n",
    "while (i < 3):\n",
    "    start = time.time()\n",
    "\n",
    "    chat_response = client.chat.completions.create(\n",
    "        # model=\"Qwen-7B-Lora_Chat\",\n",
    "        model='quant_lora',\n",
    "        messages=message_list\n",
    "    )\n",
    "    \n",
    "    end = time.time() \n",
    "    output_token = chat_response.usage.completion_tokens\n",
    "\n",
    "    print(\"Chat response:\", output_token / (end-start))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb83b68-003f-491f-ad04-e78870894d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"cuda_visible_devices\"] ='0, 5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d217332-19c8-46c1-8b03-4786a95fbeeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-15 15:44:54 config.py:211] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 05-15 15:44:54 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-AWQ/', tokenizer='/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-AWQ/', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-15 15:44:57 selector.py:16] Using FlashAttention backend.\n",
      "INFO 05-15 15:45:03 model_runner.py:104] Loading model weights took 5.5097 GB\n",
      "INFO 05-15 15:45:08 gpu_executor.py:94] # GPU blocks: 3358, # CPU blocks: 512\n",
      "INFO 05-15 15:45:13 model_runner.py:791] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-15 15:45:13 model_runner.py:795] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-15 15:45:29 model_runner.py:867] Graph capturing finished in 16 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.251198291778564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import time\n",
    "\n",
    "\n",
    "# Sample prompts.\n",
    "prompts = [\n",
    "    \"告诉我有关北京的特产\",\n",
    "] * 10 \n",
    "\n",
    "# Create a sampling params object.\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=2000)\n",
    "\n",
    "# Create an LLM.\n",
    "llm = LLM(model='/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-AWQ/',\n",
    "         quantization='awq')\n",
    "# Generate texts from the prompts. The output is a list of RequestOutput objects\n",
    "# that contain the prompt, generated text, and other information.\n",
    "start = time.time()\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f406a088-baaa-4bd4-a06b-d6b47d276ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [29:20<00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1603.8759601802674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"告诉我有关上海的特产\",\n",
    "] * 10000\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "num_tokens = sum([len(output.outputs[0].token_ids) for output in outputs]) \n",
    "spend_time = time.time() - start\n",
    "print(num_tokens / spend_time )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6b49f7-8d4c-4060-9130-9f96f7dba4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  tp    1     2\n",
    "# 1     71     \n",
    "# 10    224\n",
    "# 100   894\n",
    "# 500   1825\n",
    "# 1000  2022   2042\n",
    "# 10000 2258\n",
    "\n",
    "# 张量并行数量增大会明显降低显存占用，但是不会增大推理速度，甚至略微降低\n",
    "#       chat   quant\n",
    "# 1     71      100\n",
    "# 10    224     324\n",
    "# 100   894     910\n",
    "# 500   1825    1553\n",
    "# 1000  2022    1642\n",
    "# 10000 2258    1603\n",
    "\n",
    "# batch size 小于100时，推理速度受限于内存中传输权重的带宽，量化模型较小所以可以更快\n",
    "# batch size 大时，推理速度受限于计算，量化模型的反量化操作增加了计算资源，推理速度更慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0327b257-ef84-45a0-96ac-14ac254347c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RequestOutput(request_id=10, prompt='告诉我有关上海的特产', prompt_token_ids=[106525, 101063, 100633, 9370, 112984], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='的介绍\\n上海的特产有很多，其中比较有名的有“龙井虾仁”、“糖醋排骨”、“酱鸭”、“汤包”、“小笼包”、“松饼”、“糕点”等。其中，“龙井虾仁”是上海地区的传统名菜，以新鲜的龙井虾仁和精致的工艺制作而成；“糖醋排骨”是上海地区的经典小吃，用猪排骨烹调而成，味道酸甜可口；“酱鸭”是上海地区的传统名菜，以鸭子为主要原料，搭配独特的酱料烹制而成；“汤包”和“小笼包”是上海的特色小吃，外皮薄而馅料足，口感鲜美；“松饼”和“糕点”则是上海传统的点心，口感细腻，口味丰富。这些特色美食都是上海文化的重要组成部分，也是游客品尝上海美食的绝佳选择。', token_ids=[9370, 100157, 198, 100633, 9370, 112984, 101194, 3837, 90919, 99792, 111543, 18830, 2073, 99465, 104097, 102775, 102030, 854, 91956, 100443, 106960, 118378, 854, 91956, 102675, 105397, 854, 91956, 102022, 67279, 854, 91956, 30709, 101600, 67279, 854, 91956, 100180, 101579, 854, 91956, 101638, 27442, 854, 49567, 1773, 90919, 41505, 99465, 104097, 102775, 102030, 854, 20412, 100633, 105638, 100169, 13072, 99800, 3837, 23031, 104838, 9370, 99465, 104097, 102775, 102030, 33108, 106110, 9370, 101189, 103963, 106042, 24968, 2073, 100443, 106960, 118378, 854, 20412, 100633, 105638, 101297, 107600, 3837, 11622, 100761, 118378, 103499, 47872, 106042, 3837, 102580, 99918, 100475, 30440, 39426, 24968, 2073, 102675, 105397, 854, 20412, 100633, 105638, 100169, 13072, 99800, 3837, 23031, 105397, 44729, 111007, 104697, 3837, 104402, 105071, 102675, 41406, 103499, 43316, 106042, 24968, 2073, 102022, 67279, 854, 33108, 2073, 30709, 101600, 67279, 854, 20412, 100633, 9370, 100175, 107600, 3837, 47815, 99888, 101264, 68536, 113119, 41406, 99336, 3837, 107816, 99705, 57566, 24968, 2073, 100180, 101579, 854, 33108, 2073, 101638, 27442, 854, 104428, 100633, 105062, 27442, 63109, 3837, 107816, 108996, 3837, 107102, 100733, 1773, 100001, 100175, 104365, 100132, 100633, 99348, 101945, 106889, 3837, 100000, 104090, 110219, 100633, 104365, 9370, 118871, 50404, 1773, 151645], cumulative_logprob=-114.27743450179696, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1715755512.740602, last_token_time=1715755512.740602, first_scheduled_time=1715755512.7472637, first_token_time=1715755512.7736452, time_in_queue=0.006661653518676758, finished_time=1715755515.6755273), lora_request=None),\n",
       " RequestOutput(request_id=11, prompt='告诉我有关上海的特产', prompt_token_ids=[106525, 101063, 100633, 9370, 112984], prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='小吃的信息\\n\\n\\n\\n上海的特产小吃有很多，比如小笼包、生煎、汤包、粽子、糕点、糖醋排骨、烤麸、糟鸭等，其中小笼包和生煎是最具代表性的上海传统小吃，以其独特的口感和美味而受到人们喜爱；汤包则以其精致的工艺和鲜美的馅料著称；粽子和糕点则代表着上海的端午节文化；糖醋排骨和烤麸则是上海地区的家常菜，深受市民喜爱；糟鸭则是上海地区的传统腌制鸭肉，口感鲜美。除此之外，上海还有许多其他特色小吃，如五香豆、鲜肉月饼、酒酿圆子等，每一种都有其独特的魅力。如果您有机会去上海，不妨尝试一下这些地道的美食，体验上海的饮食文化。', token_ids=[107600, 105427, 271, 271, 100633, 9370, 112984, 107600, 101194, 3837, 101912, 30709, 101600, 67279, 5373, 21287, 108471, 5373, 102022, 67279, 5373, 118235, 5373, 101638, 27442, 5373, 100443, 106960, 118378, 5373, 102554, 120556, 5373, 103336, 105397, 49567, 3837, 90919, 30709, 101600, 67279, 33108, 21287, 108471, 104890, 76813, 99661, 104196, 100633, 100169, 107600, 3837, 109859, 105071, 107816, 33108, 106800, 68536, 100683, 100659, 102721, 24968, 102022, 67279, 46448, 109859, 106110, 9370, 101189, 33108, 99705, 101607, 113119, 41406, 99610, 24641, 24968, 118235, 33108, 101638, 27442, 46448, 112235, 100633, 9370, 118004, 55502, 99348, 24968, 100443, 106960, 118378, 33108, 102554, 120556, 104428, 100633, 105638, 45629, 38953, 99800, 3837, 106902, 102047, 102721, 24968, 103336, 105397, 104428, 100633, 105638, 100169, 119122, 43316, 105397, 99894, 3837, 107816, 99705, 57566, 1773, 107414, 3837, 100633, 100626, 100694, 92894, 100175, 107600, 3837, 29524, 75108, 99662, 99955, 5373, 99705, 99894, 112199, 5373, 99525, 101013, 100213, 44729, 49567, 3837, 73157, 101053, 101103, 41146, 105071, 102550, 1773, 106870, 106211, 85336, 100633, 3837, 107303, 104482, 100158, 100001, 110810, 9370, 104365, 3837, 101904, 100633, 9370, 104579, 99348, 1773, 151645], cumulative_logprob=-109.50437852554023, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1715755512.7427344, last_token_time=1715755512.7427344, first_scheduled_time=1715755512.7472637, first_token_time=1715755512.7736452, time_in_queue=0.004529237747192383, finished_time=1715755515.4019275), lora_request=None))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0], outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76357bdb-f280-4928-874b-e8096e9b2083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "str = '北京的特产有“北京烤鸭”、“豆汁焦圈”、“羊蝎子”和“冰糖葫芦”等，其中“北京烤鸭”是最具代表性的，它以其独特的烹饪技术和美味而闻名；“豆汁焦圈”是一种传统的北京小吃，豆汁是用绿豆发酵而成，焦圈是用面粉和糖制成；“羊蝎子”是一种独特的烹饪方法，它使用羊的脊髓，经过烹饪后变得鲜美可口；“冰糖葫芦”是一种以山楂、葡萄、苹果等水果串起来，外面包裹冰糖的特色小吃，口感酸甜可口。'\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    '/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-AWQ', # path to the output directory\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "out = tokenizer(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5667e-afb1-40a3-aabf-bb9257f3950f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "260174bf-3a6d-43cb-9a5a-adc65bf262d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16a0b5d5-0715-4f56-88d8-5dcd90077e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [68990, 9370, 112984, 18830, 2073, 68990, 102554, 105397, 854, 91956, 99955, 102514, 100479, 100044, 854, 91956, 101187, 116558, 44729, 854, 33108, 2073, 100038, 100443, 111065, 854, 49567, 3837, 90919, 2073, 68990, 102554, 105397, 854, 104890, 76813, 99661, 104196, 3837, 99652, 109859, 105071, 111611, 107772, 106800, 68536, 109836, 24968, 2073, 99955, 102514, 100479, 100044, 854, 101158, 105062, 68990, 107600, 3837, 99955, 102514, 20412, 11622, 118693, 108279, 106042, 3837, 100479, 100044, 20412, 11622, 112398, 33108, 100443, 108711, 24968, 2073, 101187, 116558, 44729, 854, 101158, 105071, 111611, 39907, 3837, 99652, 37029, 101187, 9370, 109257, 103661, 3837, 101897, 111611, 33447, 101197, 99705, 57566, 30440, 39426, 24968, 2073, 100038, 100443, 111065, 854, 101158, 23031, 57811, 121142, 5373, 101580, 5373, 104167, 49567, 104618, 51575, 99793, 3837, 102586, 108232, 100038, 100443, 9370, 100175, 107600, 3837, 107816, 99918, 100475, 30440, 39426, 1773], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5eb5c05-3b27-4e0a-b06f-74d293d11610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched '}' (3344056460.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[57], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    }'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:1212/v1/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "\"model\": \"facebook/opt-125m\",\n",
    "\"prompt\": \"San Francisco is a\",\n",
    "\"max_tokens\": 7,\n",
    "\"temperature\": 0\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae81bd6-64dc-4d42-b963-af63070c41ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
