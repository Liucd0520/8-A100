{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767cdd92-d42a-4335-95b2-d00bbd76fc27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: ChatCompletion(id='cmpl-3f2f368638ad497d91f9f6ce02ba9fbf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\\n', role='assistant', function_call=None, tool_calls=None), stop_reason=151643)], created=1715825507, model='quant_lora', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=24, prompt_tokens=90, total_tokens=114))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:1122/v1\"\n",
    "import time\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"quant_lora\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个人工智能助手.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt_template},\n",
    "    ]\n",
    ")\n",
    "print(\"Chat response:\", chat_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecb83b68-003f-491f-ad04-e78870894d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"2023-12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"2023-06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"2023-12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"2023-12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"12-30-2023\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"1970-01-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"2023-12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"2022-05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"12-30-2023\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"2021-06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"2020-04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"2021-05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"三亚\", \"date\": \"04-16\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"03-15\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"威海\", \"date\": \"05-06\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"青岛\", \"date\": \"2023-12-30\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"北京\", \"date\": \"06-01\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"01-03\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"上海\", \"date\": \"08-08\"}<|im_end|>\n",
      "\n",
      "Chat response: {\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\n",
      "\n",
      "25.018665075302124\n"
     ]
    }
   ],
   "source": [
    "prompt_template='''\n",
    "给定一句话：“%s”，请你按步骤要求工作。\n",
    "\n",
    "步骤1：识别这句话中的城市和日期共2个信息\n",
    "步骤2：根据城市和日期信息，生成JSON字符串，格式为{\"city\":城市,\"date\":日期}\n",
    "\n",
    "请问，这个JSON字符串是：\n",
    "'''\n",
    "Q_list=['2020年4月16号三亚下雨么?','青岛3-15号天气预报','5月6号下雪么, 城市是威海','青岛2023年12月30号有雾霾么?','我打算6月1号去北京旅游，请问天气怎么样？','你们打算1月3号坐哪一趟航班去上海？','小明和小红是8月8号在上海结婚么?',\n",
    "        '一起去东北看冰雕么, 大概是1月15号左右, 我们3个人一起'] * 10\n",
    "\n",
    "prompts = [prompt_template%(Q,) for Q in Q_list]\n",
    "\n",
    "from openai import OpenAI\n",
    "# Set OpenAI's API key and API base to use vLLM's API server.\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:1122/v1\"\n",
    "import time\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for prompt in prompts:\n",
    "    chat_response = client.chat.completions.create(\n",
    "        model=\"quant_lora\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"你是一个人工智能助手.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    print(\"Chat response:\",  chat_response.choices[0].message.content)\n",
    "print(time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a0e4b0-8cfa-450e-9ffb-be3e265b09b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"city\": \"东北\", \"date\": \"01-15\"}<|im_end|>\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7B-chat-Int4:      16s\n",
    "# Merge_lora-GPTQ    15s\n",
    "# Merge_lora-AWQ     19s (need float16)\n",
    "\n",
    "# Merge_lora         25s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d217332-19c8-46c1-8b03-4786a95fbeeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import time\n",
    "\n",
    "\n",
    "# Sample prompts.\n",
    "prompts = [\n",
    "    \"告诉我有关北京的特产\",\n",
    "] * 5\n",
    "\n",
    "# Create a sampling params object.\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=400, ignore_eos=True)\n",
    "\n",
    "# Create an LLM.\n",
    "llm = LLM(model='gptq_qwen/', tokenizer='gptq_qwen',  quantization='gptq',\n",
    "         trust_remote_code=True)\n",
    "\n",
    "prompt_template='''\n",
    "给定一句话：“%s”，请你按步骤要求工作。\n",
    "\n",
    "步骤1：识别这句话中的城市和日期共2个信息\n",
    "步骤2：根据城市和日期信息，生成JSON字符串，格式为{\"city\":城市,\"date\":日期}\n",
    "\n",
    "请问，这个JSON字符串是：\n",
    "'''\n",
    "\n",
    "Q_list=['2020年4月16号三亚下雨么?','青岛3-15号天气预报','5月6号下雪么, 城市是威海','青岛2023年12月30号有雾霾么?','我打算6月1号去北京旅游，请问天气怎么样？','你们打算1月3号坐哪一趟航班去上海？','小明和小红是8月8号在上海结婚么?',\n",
    "        '一起去东北看冰雕么, 大概是1月15号左右, 我们3个人一起']\n",
    "\n",
    "prompts = [prompt_template%(Q,) for Q in Q_list]\n",
    "\n",
    "start = time.time()\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "print(time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8097d2-15e3-47e3-a7a1-7018575b3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='0, 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e2f112-18c3-4a83-a3d2-51fc3b5839ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1\n"
     ]
    }
   ],
   "source": [
    "! echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22df8594-600f-4bf3-a4d3-5f3a2a26da6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 05-16 17:26:01 config.py:169] gptq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 05-16 17:26:01 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-GPTQ-Int4/', speculative_config=None, tokenizer='/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-GPTQ-Int4/', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-16 17:26:01 utils.py:608] Found nccl from library /home/liuchangdong/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 05-16 17:26:04 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 05-16 17:26:04 selector.py:33] Using XFormers backend.\n",
      "INFO 05-16 17:26:13 model_runner.py:173] Loading model weights took 5.5124 GB\n",
      "INFO 05-16 17:26:18 gpu_executor.py:119] # GPU blocks: 3578, # CPU blocks: 512\n",
      "INFO 05-16 17:26:23 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 05-16 17:26:23 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 05-16 17:26:42 model_runner.py:1057] Graph capturing finished in 19 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# Create a sampling params object.\n",
    "sampling_params = SamplingParams(temperature=0.8, top_p=0.95, max_tokens=400, ignore_eos=True)\n",
    "\n",
    "model_path = '/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-GPTQ-Int4/'\n",
    "# Create an LLM.\n",
    "llm = LLM(model= model_path, \n",
    "           quantization='gptq',\n",
    "          max_model_len=8192,  # 这个是必要的，否则\n",
    "          # tensor_parallel_size=2, gpu_memory_utilization=0.8,\n",
    "         trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70e2188e-2f74-4476-bd15-7c54a44c3157",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 有关上海的特产，这里罗列了一些具有代表性的：\n",
      "\n",
      "1. **小笼包**：上海特色小吃，以鲜肉和皮薄馅多著称，尤其是南翔馒头店的最为著名。\n",
      "\n",
      "2. **生煎**：上海人常吃的早点，底酥皮脆，里面是软嫩的猪肉和汤汁，一咬一兜油。\n",
      "\n",
      "3. **蟹壳黄**：一种酥皮点心，类似月饼，以黄油和芝麻制成，上海人逢年过节常做。\n",
      "\n",
      "4. **糟肉**：用猪五花肉腌制，再配以糟酒，口感醇厚，常作为节日菜肴。\n",
      "\n",
      "5. **上海酒酿圆子**：糯米制成的甜品，内含酒糟，甜而不腻，冬季必备。\n",
      "\n",
      "6. **杨浦糕点**：杨浦区有特色的糕点，如杏仁糕、芝麻糖等。\n",
      "\n",
      "7. **南翔蟹粉小笼**：与小笼包并列的特色小吃，蟹粉口感丰富。\n",
      "\n",
      "8. **糕团**：上海本地的糯米团，种类多样，如咸蛋黄、豆沙等口味。\n",
      "\n",
      "9. **毛豆腐**：上海特色豆制品，口感细腻，制作工艺独特。\n",
      "\n",
      "10. **鲜肉月饼**：中秋节特色，肉馅和莲蓉搭配，味道醇厚。\n",
      "\n",
      "11. **双皮奶**：甜品，上海人喜欢的乳制品，口感细腻，奶香味浓。\n",
      "\n",
      "12. **糖醋排骨**：上海家常菜，色泽红亮，酸甜可口。\n",
      "\n",
      "13. **上海炒面**：将面条炒至微黄，加入蔬菜、肉类等，是上海人的快餐。\n",
      "\n",
      "14. **阿婆豆腐**：地道上海小吃，豆腐鲜嫩，汤汁浓郁。\n",
      "\n",
      "以上只是上海特色的一部分，实际上上海美食种类繁多\n",
      "135.21338528387636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "       \"告诉我有关上海的特产有哪些？\" \n",
    "] \n",
    "\n",
    "\n",
    "start = time.time()\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "num_tokens = sum([len(output.outputs[0].token_ids) for output in outputs]) \n",
    "spend_time = time.time() - start\n",
    "print(outputs[-1].outputs[0].text)\n",
    "print(num_tokens / spend_time )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c8a90d5-bd40-43b7-b471-b63425f8cdbd",
   "metadata": {},
   "source": [
    "# model   1   10   100   1000\n",
    "7B       71   259  1526  2978\n",
    "7B-AWQ   94   432  1615  2073\n",
    "7B-GPTQ  136  428  1280  2431\n",
    "14B      40   157  1000  1378 \n",
    "14B-AWQ  66   261  927   1263\n",
    "14B-GPTQ 87   290  710   1514\n",
    "32B-AWQ  31    103  466   663\n",
    "72B-AWQ(2)27   146  303   294\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2bf6d5a-48e6-4cd3-9895-fc47aca540ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "model:   1   10   100\n",
    "7B\n",
    "7B-GPTQ  136  137  60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6b49f7-8d4c-4060-9130-9f96f7dba4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  tp    1     2\n",
    "# 1     71     \n",
    "# 10    224\n",
    "# 100   894\n",
    "# 500   1825\n",
    "# 1000  2022   2042\n",
    "# 10000 2258\n",
    "\n",
    "# 张量并行数量增大会明显降低显存占用，但是不会增大推理速度，甚至略微降低\n",
    "#       chat  AWQ(1.5) GPTQ(1.5)  MyGPTQ    GPTQ(1)\n",
    "# 1     71      100    134     135\n",
    "# 10    224     324    360     473\n",
    "# 100   894     910    980     827           827           \n",
    "# 500   1825    1553   1526    858\n",
    "# 1000  2022    1642   1828\n",
    "# 10000 2258    1603   2159\n",
    "\n",
    "# batch size 小于100时，推理速度受限于内存中传输权重的带宽，量化模型较小所以可以更快\n",
    "# batch size 大时，推理速度受限于计算，量化模型的反量化操作增加了计算资源，推理速度更慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327b257-ef84-45a0-96ac-14ac254347c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76357bdb-f280-4928-874b-e8096e9b2083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "str = '北京的特产有“北京烤鸭”、“豆汁焦圈”、“羊蝎子”和“冰糖葫芦”等，其中“北京烤鸭”是最具代表性的，它以其独特的烹饪技术和美味而闻名；“豆汁焦圈”是一种传统的北京小吃，豆汁是用绿豆发酵而成，焦圈是用面粉和糖制成；“羊蝎子”是一种独特的烹饪方法，它使用羊的脊髓，经过烹饪后变得鲜美可口；“冰糖葫芦”是一种以山楂、葡萄、苹果等水果串起来，外面包裹冰糖的特色小吃，口感酸甜可口。'\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    '/data/liucd/langchain/Qwen/Qwen1___5-7B-Chat-AWQ', # path to the output directory\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "out = tokenizer(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df5667e-afb1-40a3-aabf-bb9257f3950f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "260174bf-3a6d-43cb-9a5a-adc65bf262d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16a0b5d5-0715-4f56-88d8-5dcd90077e40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [68990, 9370, 112984, 18830, 2073, 68990, 102554, 105397, 854, 91956, 99955, 102514, 100479, 100044, 854, 91956, 101187, 116558, 44729, 854, 33108, 2073, 100038, 100443, 111065, 854, 49567, 3837, 90919, 2073, 68990, 102554, 105397, 854, 104890, 76813, 99661, 104196, 3837, 99652, 109859, 105071, 111611, 107772, 106800, 68536, 109836, 24968, 2073, 99955, 102514, 100479, 100044, 854, 101158, 105062, 68990, 107600, 3837, 99955, 102514, 20412, 11622, 118693, 108279, 106042, 3837, 100479, 100044, 20412, 11622, 112398, 33108, 100443, 108711, 24968, 2073, 101187, 116558, 44729, 854, 101158, 105071, 111611, 39907, 3837, 99652, 37029, 101187, 9370, 109257, 103661, 3837, 101897, 111611, 33447, 101197, 99705, 57566, 30440, 39426, 24968, 2073, 100038, 100443, 111065, 854, 101158, 23031, 57811, 121142, 5373, 101580, 5373, 104167, 49567, 104618, 51575, 99793, 3837, 102586, 108232, 100038, 100443, 9370, 100175, 107600, 3837, 107816, 99918, 100475, 30440, 39426, 1773], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5eb5c05-3b27-4e0a-b06f-74d293d11610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched '}' (3344056460.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[57], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    }'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:1212/v1/completions \\\n",
    "-H \"Content-Type: application/json\" \\\n",
    "-d '{\n",
    "\"model\": \"facebook/opt-125m\",\n",
    "\"prompt\": \"San Francisco is a\",\n",
    "\"max_tokens\": 7,\n",
    "\"temperature\": 0\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae81bd6-64dc-4d42-b963-af63070c41ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
